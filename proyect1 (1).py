# -*- coding: utf-8 -*-
"""PROYECT1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Duqjn-SiDB8XjyjxWdlT2awe4Gzh6wr-

# **DEEPLEARNING**
# **PROYECT 1**
**UNIVERSIDAD MILITAR NUEVA GRANADA**

**Jose Luis Pineda Barrera**

**Daniela Fuentes Bello**

# 1. Librerías
"""

import pandas as pd
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
import random
# Carga de módulos
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import mean_squared_error, mean_absolute_error  # <-- Asegúrate de importar esto

"""# 2. Training data (Dataset)

Generar datos de forma similar a anterior ejemplo

"""

# Cargar el dataset
data = pd.read_csv('/content/Dataset.csv')
df = data

# Eliminar filas con valores faltantes
df_clean = df.dropna()

# Especificar las columnas que se desean eliminar
columns_to_drop = [
    'Nombre', 'Departamento de Nacimiento','ID Departamento de Nacimiento',
    'ID Municipio de Nacimiento', 'Municipio de Nacimiento', 'Email Oficina',
    'Codigo Sigep', 'NIT Entidad', 'Orden', 'Suborden',
    'ID Departamento Entidad', 'Departamento Ubicación Entidad', 'Nivel Entidad', 'Naturaleza Jurídica',
    'Longitud Municipio Entidad', 'Latitud Municipio Entidad',
    'Denominación Empleo Actual', 'Fecha de vinculación', 'Id Municipio Entidad','Municipio Ubicación Entidad','Clasificación Organica'
]

df_clean = df_clean.drop(columns=columns_to_drop)

# Reemplazar las comas y convertir a float en todas las columnas numéricas
columns_to_convert = ['Asignación Básica Salarial', 'Meses de Experiencia Público',
                      'Meses de Experiencia Privado', 'Meses de Experiencia Docente']

for column in columns_to_convert:
    df_clean[column] = df_clean[column].replace(',', '', regex=True).astype(float)
#Encoding one-hot
df_clean = pd.get_dummies(df_clean, columns=['Sexo'], drop_first=True)
#LabelEncoding
# Identificar las columnas categóricas
categorical_columns = ['Nivel Educativo', 'Nivel Jerarquico Empleo', 'Dependencia Empleo Actual']

# Aplicar Label Encoding a todas las columnas categóricas
label_encoder = LabelEncoder()
for column in categorical_columns:
    df_clean[column] = label_encoder.fit_transform(df_clean[column])

# Verificar las primeras filas del DataFrame procesado
print("Primeras filas del DataFrame procesado:")
print(df_clean.head())

# Asignar el DataFrame limpio y codificado a 'data'
data = df_clean

# Selección de características de entrada y variable objetivo
X = df_clean[['Nivel Educativo', 'Nivel Jerarquico Empleo', 'Meses de Experiencia Público',
        'Meses de Experiencia Privado', 'Meses de Experiencia Docente', 'Dependencia Empleo Actual']]
y = df_clean['Asignación Básica Salarial']

"""# 3. Lectura del dataset por lotes

Aleatorizar y leer por minilotes
"""

# División del dataset en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

mean = X_train.mean(axis=0)
std = X_train.std(axis=0)

X_train -= mean
X_train /= std
X_test -= mean
X_test /= std

# Hiperparámetros
batch_s = 32
lr = 0.1
num_epochs = 100
optimizerf = tf.keras.optimizers.Adam(learning_rate=lr)

# Construcción del modelo de regresión
model = tf.keras.Sequential([
    tf.keras.layers.Dense(256, input_dim=X_train.shape[1], activation='relu'),
     tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1)  # Salida para regresión
])

# Compilar el modelo
model.compile(
    optimizer=optimizerf,
    loss='mean_squared_error',
    metrics=['mean_absolute_error']
)

# Entrenamiento del modelo
history = model.fit(
    X_train,
    y_train,
    epochs=num_epochs,
    batch_size=batch_s,
    validation_data=(X_test, y_test),
    verbose=1
)

# Evaluación del modelo
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)

print("Error Cuadrático Medio (MSE):", mse)
print("Error Absoluto Medio (MAE):", mae)
print("Y_pred:", y_pred)

# Visualización del rendimiento durante el entrenamiento

# Gráfica de Pérdida
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(len(loss))
plt.plot(epochs, loss, 'bo', label='Pérdida entrenamiento')
plt.plot(epochs, val_loss, 'b', label='Pérdida validación')
plt.title('Pérdida vs. No. de epochs')
plt.legend()
plt.show()

# Gráfica de MAE
mae = history.history['mean_absolute_error']
val_mae = history.history['val_mean_absolute_error']
plt.plot(epochs, mae, 'bo', label='MAE entrenamiento')
plt.plot(epochs, val_mae, 'b', label='MAE validación')
plt.title('MAE vs. No. de epochs')
plt.legend()
plt.show()